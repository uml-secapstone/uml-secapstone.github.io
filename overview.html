<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>UML-SE Capstone Project </title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
		<header id="header">
			<!-- Menu -->
			<nav id="menu">
				<ul>
					<li><a href="index.html" >Homepage</a></li>
					<li><a href="demo.html">Demo</a></li>
										<!--<li><a href="about.html">About</a></li>-->

					<li><a href="overview.html"class="active">Overview</a></li>
				</ul>
			</nav>
		</header>
		<!-- Wrapper -->
		<div id="wrapper">
			<!-- Main -->
			<div id="main">
				<div class="inner">

					<!-- Content -->
						<section>
							<header class="main">
								<h1>Project Overview</h1>
							</header>

							<!-- Content -->
								
								
								
								<h2 id="content">Adversarial Attacks</h2>
								<iframe width="560" height="315" src="https://www.youtube.com/embed/pc2ssNY98LA?si=13H6U-dOwuNX9XcA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
									<p>An adversarial attack aims to cause a misclassification in the model by imperceptibly modifying input. The 2 types of attacks we have implemented are white-box and black-box attacks: white-box attacks target models with publicly available parameters, while black-box attacks do not need information about the model but may require more computation. 
									</p>
									
								<hr class="major" />
								<h2 id="content">Language Models</h2>
									<p>Language models, like chatbots or AI assistants, are designed to generate human-like responses based on user input. We have implemented this adversarial attack towards language models, especially with a chatbox platform.
										Our goal is to trick the language models in returning responses for "unethical questions".
									</p>
								<hr class="major" />
								<h2 id="content">Anomaly Detection Model</h2>
									<p>Our implementation of an anomaly detection model aims to recognize adversarial attacks in ML, improving the security and reliability of services that use AI. Anomaly detection works by training data of normal behavior and recorded "anomalous" input, which is then effetive in discerning subtle changes that differ from normal input. </p>
									
								<hr class="major" />
								
									</div>
								</div>

						</section>

				</div>
			</div>
		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>